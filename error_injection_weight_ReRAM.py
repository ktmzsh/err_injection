"""
Summary     :       Random error injection program for segnet's weight data
Date        :       2019/12/4
Author      :       K. Mizushina

Details     :
This program is modified for ReRAM team.
Removed NAND pattern error injection functions and BER calculate functions.
Injected error pattern is completely random generated by rand() function.
"""

import pandas as pd
import numpy as np
import os
import glob
import struct
import random
import argparse
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

parser = argparse.ArgumentParser(description="Default options")
# Following argument is only for NAND chip
#parser.add_argument("--info", default=0)
args = parser.parse_args()

##### Path list
# define weight data root
original_weight_root = '/home/mizushina/python_program/segnet/Weight_data_original/'
extention_all = "*"
extention_csv = '.csv'

# list of weight list
weight_name_list = ['conv1', 'conv2', 'conv3', 'conv4',\
                    'conv_deconv1', 'conv_deconv2', 'conv_deconv3', 'conv_deconv4']


# Define Excel format file and dir
excel_dir = "Excel_file"
excel_file_name = "Bics3_#11_800K_ReadDisturb.csv"
#trans_path = os.path.join(excel_dir, excel_file_name)

pe = [1, 2, 10, 30, 100, 300, 1000, 3000, 7000, 10000, 15000, 30000, 50000, 100000,\
          200000, 300000, 400000, 500000, 600000, 700000, 800000]

date = [0, 0.0001, 0.01, 0.02, 0.04, 0.08, 0.13, 0.21, 0.29, 0.42, 0.58, 0.75,\
        1.0, 1.25, 1.5, 2.0, 2.5, 3.0]

PE_count_list = ['PE1', 'PE100', 'PE500', 'PE1K', 'PE2K', 'PE4K']

# Which PE results do you want to use?
CURRENT_TARGET = 5

target_excel_file_name = (PE_count_list[CURRENT_TARGET] + extention_csv)
trans_path = os.path.join(excel_dir, target_excel_file_name)


#output_path_dir = 'injected_weight_csv'
current_path = os.getcwd()
output_path_dir = os.path.join(current_path, 'reram')
##### Path list end

error_rate = [0.001, 0.005, 0.008, 0.01, 0.015, 0.02, 0.022, 0.025, 0.03, 0.035,
              0.04, 0.045, 0.05, 0.055, 0.06, 0.065, 0.07, 0.075, 0.08, 0.09, 0.095, 0.1,
              0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23,
              0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3]

def main():
    # オリジナルのファイルのパスを作り、すべてglobする。今回はうまく行くのでソートしてる。
    full_original_weight = os.path.join(original_weight_root, extention_all + extention_csv)
    weight_csv_list = glob.glob(full_original_weight)
    weight_csv_list.sort()
    print("Number of weight : ", len(weight_csv_list))
    print("Path of weight data : ", weight_csv_list)

    # 外側のループは8個の重みをすべて調整するときに回す。内側のループはリテンションのデータを扱う。
    for current_weight_num in range(8): #0:conv1, ... , 7:deconv4
        for inject_ber in range(42):  #0:day0,...,16:day2.5
            # このときのnamesはつけておかないと事故ることがあるので保険のためにつけてる。
            df = pd.read_csv(weight_csv_list[current_weight_num], delimiter=',', header=None, names='A')
            arr = df.values
            parameter_num = arr.shape[0]
            error_cell_num = int(parameter_num * error_rate[inject_ber])

            print("weight contains {} params.".format(parameter_num))
            print("Progress... \ncurrently T_BER is {}".format(error_rate[inject_ber]))
            print("...almost {} params causes errors.".format(error_cell_num))

            for i in range(parameter_num):
                if (random.random() < error_rate[inject_ber]):
                    #print(arr[i])
                    float_temp = float(arr[i])
                    bin_data = struct.pack('>d', float_temp)
                    mod_data = struct.unpack('>Q', bin_data)
                    mod_data = bin(mod_data[0])
                    mod_data = (mod_data)
                    mod_data = int(mod_data, 2)
                    #print("Ordinal int : ", (mod_data))
                    #########################################このパラメータでエラーの調整ができる###########################
                    mod_data = (mod_data - random.randint(0, 10000000000000))
                    #print("Shifted int : ", (mod_data))
                    mod_data = struct.pack('>Q', mod_data)
                    mod_data = struct.unpack('>d', mod_data)
                    #print("mod test : {}".format((mod_data)))

                    arr[i] = mod_data
                    #print(arr[i])

            save_df = pd.DataFrame(arr)
            print(error_rate[inject_ber])
            temp_err_name = str(error_rate[inject_ber])
            output_name = os.path.join(output_path_dir, temp_err_name,  weight_name_list[current_weight_num] + '_' + str(error_rate[inject_ber]) +extention_csv)
            print("See result : ",output_name)
            save_df.to_csv(output_name, header=None, index=None)


if __name__ == "__main__":
    main()